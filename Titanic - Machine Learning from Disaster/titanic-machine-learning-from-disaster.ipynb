{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":332.100135,"end_time":"2025-10-18T00:11:43.415478","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-18T00:06:11.315343","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"afc456c2-0a6e-4b07-ad9b-433fdabe16ad","cell_type":"code","source":"# Cell 1: Setup environment\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:08:39.804122Z","iopub.execute_input":"2025-12-25T14:08:39.804458Z","iopub.status.idle":"2025-12-25T14:08:39.810493Z","shell.execute_reply.started":"2025-12-25T14:08:39.804435Z","shell.execute_reply":"2025-12-25T14:08:39.809278Z"}},"outputs":[],"execution_count":3},{"id":"fea1d34b-fe25-4a0f-95d0-8ba057308f7f","cell_type":"code","source":"# Cell 2: Import libraries\nimport tensorflow as tf\ntf.get_logger().setLevel('ERROR')\nimport tensorflow_decision_forests as tfdf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:11:32.199312Z","iopub.execute_input":"2025-12-25T14:11:32.199668Z","iopub.status.idle":"2025-12-25T14:11:32.204992Z","shell.execute_reply.started":"2025-12-25T14:11:32.199644Z","shell.execute_reply":"2025-12-25T14:11:32.203976Z"}},"outputs":[],"execution_count":9},{"id":"aa640a16-ddb0-48c5-a441-2d5d828e7a8c","cell_type":"code","source":"# Cell 3: Load data\ntrain_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nserving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:11:33.616760Z","iopub.execute_input":"2025-12-25T14:11:33.617083Z","iopub.status.idle":"2025-12-25T14:11:33.632311Z","shell.execute_reply.started":"2025-12-25T14:11:33.617060Z","shell.execute_reply":"2025-12-25T14:11:33.631131Z"}},"outputs":[],"execution_count":10},{"id":"834c43c0-c0ed-4ff1-b7aa-16235f018a5c","cell_type":"code","source":"# Cell 4: Preprocessing\ndef preprocess(df):\n    df = df.copy()\n    df[\"Name\"] = df[\"Name\"].apply(lambda x: \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")]))\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(lambda x: x.split(\" \")[-1])\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(lambda x: \"NONE\" if len(x.split(\" \")) == 1 else \"_\".join(x.split(\" \")[0:-1]))\n    return df\n\npreprocessed_train_df = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:11:57.440696Z","iopub.execute_input":"2025-12-25T14:11:57.441085Z","iopub.status.idle":"2025-12-25T14:11:57.454916Z","shell.execute_reply.started":"2025-12-25T14:11:57.441052Z","shell.execute_reply":"2025-12-25T14:11:57.453835Z"}},"outputs":[],"execution_count":11},{"id":"da4c92e7-17fb-4e96-b8cb-efcf5e25e09f","cell_type":"code","source":"# Cell 5: Feature selection\ninput_features = ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:12:03.865410Z","iopub.execute_input":"2025-12-25T14:12:03.865724Z","iopub.status.idle":"2025-12-25T14:12:03.870993Z","shell.execute_reply.started":"2025-12-25T14:12:03.865704Z","shell.execute_reply":"2025-12-25T14:12:03.870025Z"}},"outputs":[],"execution_count":12},{"id":"1898e3a9-7aa4-489b-bdaa-67e9abc015ce","cell_type":"code","source":"# Cell 6: Create datasets\ndef tokenize_names(features, labels=None):\n    features[\"Name\"] = tf.strings.split(features[\"Name\"])\n    return features, labels\n\nimport warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df, label=\"Survived\").map(tokenize_names)\n    serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:13:30.514432Z","iopub.execute_input":"2025-12-25T14:13:30.515336Z","iopub.status.idle":"2025-12-25T14:13:30.646322Z","shell.execute_reply.started":"2025-12-25T14:13:30.515304Z","shell.execute_reply":"2025-12-25T14:13:30.645321Z"}},"outputs":[],"execution_count":15},{"id":"ec2a4b4a-2067-4e9c-9947-84f6e77901c5","cell_type":"code","source":"# Cell 7: Train ensemble\npredictions = None\nnum_predictions = 0\n\nfor i in range(100):\n    model = tfdf.keras.GradientBoostedTreesModel(\n        verbose=0,\n        features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n        exclude_non_specified_features=True,\n        random_seed=i,\n        honest=True,\n    )\n    model.fit(train_ds)\n    \n    sub_predictions = model.predict(serving_ds, verbose=0)[:,0]\n    if predictions is None:\n        predictions = sub_predictions\n    else:\n        predictions += sub_predictions\n    num_predictions += 1\n\npredictions /= num_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:13:45.453243Z","iopub.execute_input":"2025-12-25T14:13:45.453628Z","iopub.status.idle":"2025-12-25T14:15:38.565933Z","shell.execute_reply.started":"2025-12-25T14:13:45.453603Z","shell.execute_reply":"2025-12-25T14:15:38.564816Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1766672029.529177   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672029.530249   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672029.530272   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672029.531332   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672029.531355   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672029.532243   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672029.532774   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672029.533018   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672029.533286   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672029.534171   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672029.534298   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672029.534676   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 0\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672029.535177   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpkpfhk5lb/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672029.535796   18010 kernel.cc:895] Train model\nI0000 00:00:1766672029.753937   18010 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880514\nI0000 00:00:1766672029.757376   18010 kernel.cc:926] Export model in log directory: /tmp/tmpkpfhk5lb with prefix 33d5196e56664d8e\nI0000 00:00:1766672029.759617   18010 kernel.cc:944] Save model in resources\nI0000 00:00:1766672029.762495   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.880514\n\nAccuracy: 0.797872  CI95[W][0 1]\nErrorRate: : 0.202128\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  52   8\n2  11  23\nTotal: 94\n\n\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1766672029.793979   17899 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\nI0000 00:00:1766672029.794568   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672031.369866   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672031.369911   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672031.369921   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672031.370378   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672031.370401   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672031.371383   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672031.371930   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672031.372155   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672031.372430   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672031.373115   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672031.373167   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672031.373520   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 1\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672031.373632   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp_fnypudg/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672031.373826   18265 kernel.cc:895] Train model\nI0000 00:00:1766672032.016119   18265 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691023\nI0000 00:00:1766672032.023116   18265 kernel.cc:926] Export model in log directory: /tmp/tmp_fnypudg with prefix 42de4778001d4465\nI0000 00:00:1766672032.027117   18265 kernel.cc:944] Save model in resources\nI0000 00:00:1766672032.029205   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.691023\n\nAccuracy: 0.861111  CI95[W][0 1]\nErrorRate: : 0.138889\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  62   9\n2   6  31\nTotal: 108\n\n\nI0000 00:00:1766672032.724311   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672032.724350   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672032.724360   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672032.724790   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672032.724812   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672032.725693   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672032.726222   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672032.726454   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672032.726725   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672032.727431   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672032.727480   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672032.727846   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 2\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672032.727947   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpum3b3u8c/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672032.728151   18990 kernel.cc:895] Train model\nI0000 00:00:1766672032.951186   18990 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.818454\nI0000 00:00:1766672032.954441   18990 kernel.cc:926] Export model in log directory: /tmp/tmpum3b3u8c with prefix 05195915ff754ba8\nI0000 00:00:1766672032.955753   18990 kernel.cc:944] Save model in resources\nI0000 00:00:1766672032.957567   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.818454\n\nAccuracy: 0.804598  CI95[W][0 1]\nErrorRate: : 0.195402\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  41   3\n2  14  29\nTotal: 87\n\n\nI0000 00:00:1766672033.613920   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672033.613962   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672033.613974   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672033.614518   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672033.614547   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672033.615513   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672033.616180   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672033.616468   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672033.616762   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672033.617555   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672033.617602   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672033.618068   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 3\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672033.618187   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpn_xgfnmk/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672033.618357   19255 kernel.cc:895] Train model\nI0000 00:00:1766672034.463936   19255 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.766689\nI0000 00:00:1766672034.473562   19255 kernel.cc:926] Export model in log directory: /tmp/tmpn_xgfnmk with prefix 21fc775b0e3543c9\nI0000 00:00:1766672034.478666   19255 kernel.cc:944] Save model in resources\nI0000 00:00:1766672034.480603   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.766689\n\nAccuracy: 0.822917  CI95[W][0 1]\nErrorRate: : 0.177083\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  51   2\n2  15  28\nTotal: 96\n\n\nI0000 00:00:1766672035.181350   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672035.181393   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672035.181403   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672035.181798   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672035.181821   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672035.182730   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672035.183279   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672035.183553   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672035.183865   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672035.184549   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672035.184594   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672035.184956   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 4\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672035.185100   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmph6ov68he/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672035.185264   20185 kernel.cc:895] Train model\nI0000 00:00:1766672035.450781   20185 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871509\nI0000 00:00:1766672035.454419   20185 kernel.cc:926] Export model in log directory: /tmp/tmph6ov68he with prefix f04c037fe9c3475b\nI0000 00:00:1766672035.455837   20185 kernel.cc:944] Save model in resources\nI0000 00:00:1766672035.457689   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.871509\n\nAccuracy: 0.806452  CI95[W][0 1]\nErrorRate: : 0.193548\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  54  10\n2   8  21\nTotal: 93\n\n\nI0000 00:00:1766672036.110851   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672036.110894   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672036.110907   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672036.111407   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672036.111434   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672036.112319   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672036.112804   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672036.113028   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672036.113289   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672036.113906   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672036.113950   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672036.114366   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 5\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672036.114469   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpgma_swq9/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672036.114649   20482 kernel.cc:895] Train model\nI0000 00:00:1766672036.315671   20482 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.950615\nI0000 00:00:1766672036.318654   20482 kernel.cc:926] Export model in log directory: /tmp/tmpgma_swq9 with prefix 0357a5e2bde14948\nI0000 00:00:1766672036.319646   20482 kernel.cc:944] Save model in resources\nI0000 00:00:1766672036.321645   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.950615\n\nAccuracy: 0.769231  CI95[W][0 1]\nErrorRate: : 0.230769\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  46  10\n2  11  24\nTotal: 91\n\n\nI0000 00:00:1766672036.985478   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672036.985520   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672036.985533   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672036.986082   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672036.986109   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672036.986937   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672036.987519   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672036.987804   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672036.988099   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672036.988810   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672036.988857   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672036.989324   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 6\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672036.989448   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpdc1wxdk5/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672036.989620   20703 kernel.cc:895] Train model\nI0000 00:00:1766672037.346131   20703 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.794808\nI0000 00:00:1766672037.350310   20703 kernel.cc:926] Export model in log directory: /tmp/tmpdc1wxdk5 with prefix 5bd73bafd1a74cff\nI0000 00:00:1766672037.352211   20703 kernel.cc:944] Save model in resources\nI0000 00:00:1766672037.353987   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.794808\n\nAccuracy: 0.814433  CI95[W][0 1]\nErrorRate: : 0.185567\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   7\n2  11  31\nTotal: 97\n\n\nI0000 00:00:1766672038.016550   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672038.016593   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672038.016603   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672038.017040   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672038.017066   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672038.017933   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672038.018585   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672038.018910   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672038.019264   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672038.019965   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672038.020032   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672038.020459   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 7\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672038.020657   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpdbkd4zv6/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672038.020842   21052 kernel.cc:895] Train model\nI0000 00:00:1766672038.705535   21052 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.738632\nI0000 00:00:1766672038.712840   21052 kernel.cc:926] Export model in log directory: /tmp/tmpdbkd4zv6 with prefix 1073b62699d84e35\nI0000 00:00:1766672038.716833   21052 kernel.cc:944] Save model in resources\nI0000 00:00:1766672038.718682   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.738632\n\nAccuracy: 0.845238  CI95[W][0 1]\nErrorRate: : 0.154762\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  51   5\n2   8  20\nTotal: 84\n\n\nI0000 00:00:1766672039.410636   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672039.410680   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672039.410693   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672039.411158   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672039.411174   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672039.412468   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672039.413059   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672039.413294   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672039.413613   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672039.414478   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672039.414531   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672039.414910   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 8\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672039.415036   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp1j_es2jx/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672039.415236   21801 kernel.cc:895] Train model\nI0000 00:00:1766672039.802329   21801 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.812897\nI0000 00:00:1766672039.807091   21801 kernel.cc:926] Export model in log directory: /tmp/tmp1j_es2jx with prefix 2e180ba2171c4bbf\nI0000 00:00:1766672039.809708   21801 kernel.cc:944] Save model in resources\nI0000 00:00:1766672039.811761   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.812897\n\nAccuracy: 0.819277  CI95[W][0 1]\nErrorRate: : 0.180723\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  42   6\n2   9  26\nTotal: 83\n\n\nI0000 00:00:1766672039.838206   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672040.487137   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672040.487174   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672040.487186   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672040.487692   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672040.487714   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672040.488599   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672040.489184   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672040.489475   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672040.489763   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672040.490579   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672040.490638   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672040.491044   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 9\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672040.491171   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpth8fpmoj/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672040.491368   22214 kernel.cc:895] Train model\nI0000 00:00:1766672041.008319   22214 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.798368\nI0000 00:00:1766672041.015142   22214 kernel.cc:926] Export model in log directory: /tmp/tmpth8fpmoj with prefix f5cc54e404f24be7\nI0000 00:00:1766672041.018730   22214 kernel.cc:944] Save model in resources\nI0000 00:00:1766672041.020654   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.798368\n\nAccuracy: 0.831579  CI95[W][0 1]\nErrorRate: : 0.168421\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  54   6\n2  10  25\nTotal: 95\n\n\nI0000 00:00:1766672041.696674   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672041.696716   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672041.696725   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672041.697175   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672041.697191   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672041.697925   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672041.698557   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672041.698808   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672041.699084   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672041.699707   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672041.699752   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672041.700139   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 10\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672041.700257   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmph_p4xs_5/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672041.700437   22795 kernel.cc:895] Train model\nI0000 00:00:1766672041.962353   22795 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.793663\nI0000 00:00:1766672041.965994   22795 kernel.cc:926] Export model in log directory: /tmp/tmph_p4xs_5 with prefix 6631a4bdddaf4e80\nI0000 00:00:1766672041.967569   22795 kernel.cc:944] Save model in resources\nI0000 00:00:1766672041.969495   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.793663\n\nAccuracy: 0.84375  CI95[W][0 1]\nErrorRate: : 0.15625\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  46   5\n2  10  35\nTotal: 96\n\n\nI0000 00:00:1766672042.623612   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672042.623653   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672042.623665   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672042.624136   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672042.624167   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672042.625088   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672042.625580   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672042.625788   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672042.626037   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672042.626668   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672042.626716   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672042.627243   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 11\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672042.627376   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpczv41bry/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672042.627551   23096 kernel.cc:895] Train model\nI0000 00:00:1766672043.124341   23096 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.740543\nI0000 00:00:1766672043.129966   23096 kernel.cc:926] Export model in log directory: /tmp/tmpczv41bry with prefix 077f713577f24b7a\nI0000 00:00:1766672043.133132   23096 kernel.cc:944] Save model in resources\nI0000 00:00:1766672043.135093   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.740543\n\nAccuracy: 0.870588  CI95[W][0 1]\nErrorRate: : 0.129412\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  53   2\n2   9  21\nTotal: 85\n\n\nI0000 00:00:1766672043.802161   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672043.802200   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672043.802209   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672043.802659   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672043.802687   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672043.803572   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672043.804150   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672043.804375   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672043.804653   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672043.805346   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672043.805394   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672043.805749   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 12\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672043.805879   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpms32sh37/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672043.806083   23661 kernel.cc:895] Train model\nI0000 00:00:1766672044.062546   23661 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.813445\nI0000 00:00:1766672044.065988   23661 kernel.cc:926] Export model in log directory: /tmp/tmpms32sh37 with prefix 4e046741a84b4618\nI0000 00:00:1766672044.067547   23661 kernel.cc:944] Save model in resources\nI0000 00:00:1766672044.069471   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.813445\n\nAccuracy: 0.804878  CI95[W][0 1]\nErrorRate: : 0.195122\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  42   6\n2  10  24\nTotal: 82\n\n\nI0000 00:00:1766672044.727718   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672044.727762   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672044.727775   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672044.728387   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672044.728408   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672044.729299   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672044.729856   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672044.730155   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672044.730439   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672044.731190   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672044.731238   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672044.731579   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 13\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672044.731683   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpuq_xt23u/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672044.731865   23970 kernel.cc:895] Train model\nI0000 00:00:1766672045.130949   23970 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683314\nI0000 00:00:1766672045.135732   23970 kernel.cc:926] Export model in log directory: /tmp/tmpuq_xt23u with prefix fe44a75b37d94c7c\nI0000 00:00:1766672045.138384   23970 kernel.cc:944] Save model in resources\nI0000 00:00:1766672045.140258   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.683314\n\nAccuracy: 0.85567  CI95[W][0 1]\nErrorRate: : 0.14433\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  60   4\n2  10  23\nTotal: 97\n\n\nI0000 00:00:1766672045.825837   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672045.825881   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672045.825894   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672045.826487   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672045.826514   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672045.827340   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672045.827825   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672045.828054   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672045.828394   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672045.829180   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672045.829231   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672045.829606   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 14\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672045.829711   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpulegm8c2/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672045.829932   24439 kernel.cc:895] Train model\nI0000 00:00:1766672046.091491   24439 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.847284\nI0000 00:00:1766672046.094990   24439 kernel.cc:926] Export model in log directory: /tmp/tmpulegm8c2 with prefix 113a31c696564980\nI0000 00:00:1766672046.096677   24439 kernel.cc:944] Save model in resources\nI0000 00:00:1766672046.098574   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.847284\n\nAccuracy: 0.853659  CI95[W][0 1]\nErrorRate: : 0.146341\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  45   2\n2  10  25\nTotal: 82\n\n\nI0000 00:00:1766672046.764229   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672046.764274   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672046.764288   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672046.764808   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672046.764833   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672046.765699   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672046.766287   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672046.766548   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672046.766814   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672046.767479   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672046.767527   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672046.767886   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 15\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672046.767988   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpocg4hc47/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672046.768294   24752 kernel.cc:895] Train model\nI0000 00:00:1766672047.077676   24752 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880985\nI0000 00:00:1766672047.081704   24752 kernel.cc:926] Export model in log directory: /tmp/tmpocg4hc47 with prefix 15c8e6f9777e4929\nI0000 00:00:1766672047.083534   24752 kernel.cc:944] Save model in resources\nI0000 00:00:1766672047.085495   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.880985\n\nAccuracy: 0.860215  CI95[W][0 1]\nErrorRate: : 0.139785\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  59   3\n2  10  21\nTotal: 93\n\n\nI0000 00:00:1766672047.763767   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672047.763809   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672047.763819   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672047.764278   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672047.764297   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672047.765223   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672047.765774   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672047.766072   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672047.766336   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672047.766991   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672047.767074   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672047.767494   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 16\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672047.767611   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmphgt41z_a/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672047.767796   25097 kernel.cc:895] Train model\nI0000 00:00:1766672048.233242   25097 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.803151\nI0000 00:00:1766672048.238459   25097 kernel.cc:926] Export model in log directory: /tmp/tmphgt41z_a with prefix 4ef032d33cf444da\nI0000 00:00:1766672048.241245   25097 kernel.cc:944] Save model in resources\nI0000 00:00:1766672048.243088   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.803151\n\nAccuracy: 0.8  CI95[W][0 1]\nErrorRate: : 0.2\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  51   6\n2  12  21\nTotal: 90\n\n\nI0000 00:00:1766672048.920402   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672048.920447   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672048.920462   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672048.920984   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672048.921041   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672048.921888   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672048.922483   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672048.922763   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672048.923116   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672048.923789   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672048.923837   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672048.924292   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 17\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672048.924405   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp_tri_w1i/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672048.924635   25626 kernel.cc:895] Train model\nI0000 00:00:1766672049.415463   25626 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.723168\nI0000 00:00:1766672049.421446   25626 kernel.cc:926] Export model in log directory: /tmp/tmp_tri_w1i with prefix 981548e2478c4d0b\nI0000 00:00:1766672049.424446   25626 kernel.cc:944] Save model in resources\nI0000 00:00:1766672049.426318   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.723168\n\nAccuracy: 0.857143  CI95[W][0 1]\nErrorRate: : 0.142857\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   4\n2   9  30\nTotal: 91\n\n\nI0000 00:00:1766672050.547738   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672050.547792   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672050.547804   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672050.548550   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672050.548579   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672050.549677   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672050.550386   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672050.550834   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672050.551150   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672050.551840   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672050.551894   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672050.552293   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 18\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672050.552426   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpvidawhk1/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672050.552598   26171 kernel.cc:895] Train model\nI0000 00:00:1766672050.979134   26171 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.781828\nI0000 00:00:1766672050.984248   26171 kernel.cc:926] Export model in log directory: /tmp/tmpvidawhk1 with prefix caa6920a73b4435a\nI0000 00:00:1766672050.986838   26171 kernel.cc:944] Save model in resources\nI0000 00:00:1766672050.989090   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.781828\n\nAccuracy: 0.862069  CI95[W][0 1]\nErrorRate: : 0.137931\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  46   3\n2   9  29\nTotal: 87\n\n\nI0000 00:00:1766672051.020755   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672051.696684   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672051.696733   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672051.696748   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672051.697360   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672051.697390   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672051.698390   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672051.698900   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672051.699208   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672051.699496   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672051.700220   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672051.700270   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672051.700662   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 19\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672051.700780   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpf66zs8q2/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672051.701300   26652 kernel.cc:895] Train model\nI0000 00:00:1766672052.300437   26652 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.71869\nI0000 00:00:1766672052.307602   26652 kernel.cc:926] Export model in log directory: /tmp/tmpf66zs8q2 with prefix 70fc970f204b4586\nI0000 00:00:1766672052.311342   26652 kernel.cc:944] Save model in resources\nI0000 00:00:1766672052.313262   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.71869\n\nAccuracy: 0.83871  CI95[W][0 1]\nErrorRate: : 0.16129\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  41   7\n2   8  37\nTotal: 93\n\n\nI0000 00:00:1766672053.003354   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672053.003400   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672053.003411   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672053.003803   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672053.003829   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672053.004731   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672053.005309   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672053.005569   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672053.005846   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672053.006543   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672053.006622   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672053.006959   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 20\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672053.007101   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmppgkg382r/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672053.007325   27349 kernel.cc:895] Train model\nI0000 00:00:1766672053.524328   27349 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652788\nI0000 00:00:1766672053.530706   27349 kernel.cc:926] Export model in log directory: /tmp/tmppgkg382r with prefix 99a4f37ab4b04b3c\nI0000 00:00:1766672053.534144   27349 kernel.cc:944] Save model in resources\nI0000 00:00:1766672053.536240   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.652788\n\nAccuracy: 0.858696  CI95[W][0 1]\nErrorRate: : 0.141304\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  55   4\n2   9  24\nTotal: 92\n\n\nI0000 00:00:1766672054.212902   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672054.212943   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672054.212954   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672054.213354   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672054.213378   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672054.214248   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672054.214809   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672054.215066   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672054.215345   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672054.215979   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672054.216058   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672054.216485   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 21\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672054.216601   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmph33a4oki/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672054.216788   27954 kernel.cc:895] Train model\nI0000 00:00:1766672054.451189   27954 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.921663\nI0000 00:00:1766672054.454264   27954 kernel.cc:926] Export model in log directory: /tmp/tmph33a4oki with prefix d95f026c8b2b4d57\nI0000 00:00:1766672054.455641   27954 kernel.cc:944] Save model in resources\nI0000 00:00:1766672054.457488   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.921663\n\nAccuracy: 0.769231  CI95[W][0 1]\nErrorRate: : 0.230769\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  41   3\n2  15  19\nTotal: 78\n\n\nI0000 00:00:1766672055.120917   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672055.120957   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672055.120968   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672055.121499   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672055.121519   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672055.122418   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672055.122951   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672055.123223   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672055.123517   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672055.124193   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672055.124238   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672055.124728   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 22\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672055.124857   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp6sftnjzc/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672055.125105   28235 kernel.cc:895] Train model\nI0000 00:00:1766672055.369696   28235 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.0161\nI0000 00:00:1766672055.373125   28235 kernel.cc:926] Export model in log directory: /tmp/tmp6sftnjzc with prefix 8858dae6992e4666\nI0000 00:00:1766672055.374580   28235 kernel.cc:944] Save model in resources\nI0000 00:00:1766672055.376440   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 1.0161\n\nAccuracy: 0.741935  CI95[W][0 1]\nErrorRate: : 0.258065\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  49   7\n2  17  20\nTotal: 93\n\n\nI0000 00:00:1766672056.029273   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672056.029313   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672056.029328   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672056.029834   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672056.029852   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672056.030766   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672056.031341   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672056.031601   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672056.031871   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672056.032543   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672056.032589   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672056.032942   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 23\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672056.033078   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpo1nhmwpe/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672056.033276   28528 kernel.cc:895] Train model\nI0000 00:00:1766672056.362912   28528 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.797815\nI0000 00:00:1766672056.368738   28528 kernel.cc:926] Export model in log directory: /tmp/tmpo1nhmwpe with prefix ecd8c2c8cd1c4d3b\nI0000 00:00:1766672056.371096   28528 kernel.cc:944] Save model in resources\nI0000 00:00:1766672056.373275   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.797815\n\nAccuracy: 0.814433  CI95[W][0 1]\nErrorRate: : 0.185567\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  54   2\n2  16  25\nTotal: 97\n\n\nI0000 00:00:1766672057.052307   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672057.052358   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672057.052373   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672057.053000   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672057.053053   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672057.053973   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672057.054566   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672057.054831   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672057.055115   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672057.055790   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672057.055838   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672057.056284   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 24\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672057.056395   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp8y06_q6a/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672057.056605   28925 kernel.cc:895] Train model\nI0000 00:00:1766672057.313435   28925 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.854416\nI0000 00:00:1766672057.316914   28925 kernel.cc:926] Export model in log directory: /tmp/tmp8y06_q6a with prefix 31ef7696939046d8\nI0000 00:00:1766672057.318492   28925 kernel.cc:944] Save model in resources\nI0000 00:00:1766672057.320381   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.854416\n\nAccuracy: 0.861386  CI95[W][0 1]\nErrorRate: : 0.138614\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  59   4\n2  10  28\nTotal: 101\n\n\nI0000 00:00:1766672057.979613   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672057.979658   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672057.979668   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672057.980078   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672057.980095   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672057.980854   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672057.981424   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672057.981649   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672057.981892   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672057.982553   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672057.982603   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672057.982971   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 25\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672057.983108   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpgmw86ebj/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672057.983924   29234 kernel.cc:895] Train model\nI0000 00:00:1766672058.414640   29234 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.726991\nI0000 00:00:1766672058.420310   29234 kernel.cc:926] Export model in log directory: /tmp/tmpgmw86ebj with prefix e49d2f4578c54a6f\nI0000 00:00:1766672058.422900   29234 kernel.cc:944] Save model in resources\nI0000 00:00:1766672058.424853   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.726991\n\nAccuracy: 0.846154  CI95[W][0 1]\nErrorRate: : 0.153846\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   4\n2  10  29\nTotal: 91\n\n\nI0000 00:00:1766672059.092669   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672059.092712   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672059.092727   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672059.093270   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672059.093302   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672059.094186   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672059.094684   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672059.094880   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672059.095184   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672059.095821   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672059.095865   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672059.096211   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 26\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672059.096313   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpyopdwzka/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672059.096505   29719 kernel.cc:895] Train model\nI0000 00:00:1766672059.488020   29719 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62687\nI0000 00:00:1766672059.496651   29719 kernel.cc:926] Export model in log directory: /tmp/tmpyopdwzka with prefix 961c091fa50648a3\nI0000 00:00:1766672059.501481   29719 kernel.cc:944] Save model in resources\nI0000 00:00:1766672059.503586   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.62687\n\nAccuracy: 0.873418  CI95[W][0 1]\nErrorRate: : 0.126582\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  44   4\n2   6  25\nTotal: 79\n\n\nI0000 00:00:1766672060.171912   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672060.171953   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672060.171963   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672060.172470   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672060.172496   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672060.173347   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672060.173887   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672060.174147   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672060.174434   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672060.175115   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672060.175162   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672060.175556   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 27\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672060.175661   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp777_n6r1/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672060.175834   30148 kernel.cc:895] Train model\nI0000 00:00:1766672060.460864   30148 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624537\nI0000 00:00:1766672060.464642   30148 kernel.cc:926] Export model in log directory: /tmp/tmp777_n6r1 with prefix 810763be9b484922\nI0000 00:00:1766672060.466310   30148 kernel.cc:944] Save model in resources\nI0000 00:00:1766672060.468199   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.624537\n\nAccuracy: 0.857143  CI95[W][0 1]\nErrorRate: : 0.142857\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  50   6\n2   7  28\nTotal: 91\n\n\nI0000 00:00:1766672060.489374   17899 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\nI0000 00:00:1766672061.145609   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672061.145653   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672061.145667   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672061.146226   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672061.146249   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672061.147155   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672061.147721   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672061.147979   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672061.148264   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672061.148909   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672061.148954   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672061.149398   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 28\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672061.149502   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpqygchkis/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672061.149740   30465 kernel.cc:895] Train model\nI0000 00:00:1766672061.393192   30465 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872476\nI0000 00:00:1766672061.397259   30465 kernel.cc:926] Export model in log directory: /tmp/tmpqygchkis with prefix ed6f8fc8135140f4\nI0000 00:00:1766672061.398828   30465 kernel.cc:944] Save model in resources\nI0000 00:00:1766672061.400764   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.872476\n\nAccuracy: 0.813953  CI95[W][0 1]\nErrorRate: : 0.186047\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  45   5\n2  11  25\nTotal: 86\n\n\nI0000 00:00:1766672061.422567   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672062.069027   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672062.069074   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672062.069089   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672062.069446   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672062.069460   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672062.070500   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672062.071200   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672062.071499   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672062.071807   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672062.072610   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672062.072672   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672062.073086   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 29\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672062.073302   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp8xskp0ij/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672062.073495   30746 kernel.cc:895] Train model\nI0000 00:00:1766672062.529980   30746 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.77431\nI0000 00:00:1766672062.535281   30746 kernel.cc:926] Export model in log directory: /tmp/tmp8xskp0ij with prefix 47221ab5cd9049b1\nI0000 00:00:1766672062.538169   30746 kernel.cc:944] Save model in resources\nI0000 00:00:1766672062.539896   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.77431\n\nAccuracy: 0.858586  CI95[W][0 1]\nErrorRate: : 0.141414\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  59   3\n2  11  26\nTotal: 99\n\n\nI0000 00:00:1766672063.208945   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672063.208991   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672063.209030   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672063.209456   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672063.209476   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672063.210331   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672063.210826   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672063.211076   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672063.211299   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672063.211955   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672063.212023   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672063.212367   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 30\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672063.212467   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp91k_p2w6/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672063.212639   31279 kernel.cc:895] Train model\nI0000 00:00:1766672064.029770   31279 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.575245\nI0000 00:00:1766672064.038892   31279 kernel.cc:926] Export model in log directory: /tmp/tmp91k_p2w6 with prefix 2ee4103d806c4220\nI0000 00:00:1766672064.044051   31279 kernel.cc:944] Save model in resources\nI0000 00:00:1766672064.045879   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.575245\n\nAccuracy: 0.888889  CI95[W][0 1]\nErrorRate: : 0.111111\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  52   4\n2   6  28\nTotal: 90\n\n\nI0000 00:00:1766672064.742765   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672064.742810   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672064.742821   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672064.743268   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672064.743299   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672064.744323   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672064.744890   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672064.745154   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672064.745424   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672064.746147   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672064.746196   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672064.746586   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 31\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672064.746702   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpfw5vq6p4/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672064.746901   32216 kernel.cc:895] Train model\nI0000 00:00:1766672065.089748   32216 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673288\nI0000 00:00:1766672065.094841   32216 kernel.cc:926] Export model in log directory: /tmp/tmpfw5vq6p4 with prefix 90f8f80416c84b91\nI0000 00:00:1766672065.097172   32216 kernel.cc:944] Save model in resources\nI0000 00:00:1766672065.098983   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.673288\n\nAccuracy: 0.842697  CI95[W][0 1]\nErrorRate: : 0.157303\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  47   7\n2   7  28\nTotal: 89\n\n\nI0000 00:00:1766672065.758575   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672065.758618   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672065.758628   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672065.759036   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672065.759069   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672065.759913   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672065.760480   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672065.760730   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672065.760979   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672065.761751   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672065.761808   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672065.762216   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 32\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672065.762344   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpd3830mme/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672065.762517   32621 kernel.cc:895] Train model\nI0000 00:00:1766672066.000662   32621 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880624\nI0000 00:00:1766672066.004145   32621 kernel.cc:926] Export model in log directory: /tmp/tmpd3830mme with prefix 809d8453e6384bdc\nI0000 00:00:1766672066.005596   32621 kernel.cc:944] Save model in resources\nI0000 00:00:1766672066.007429   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.880624\n\nAccuracy: 0.809524  CI95[W][0 1]\nErrorRate: : 0.190476\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  42   4\n2  12  26\nTotal: 84\n\n\nI0000 00:00:1766672066.664090   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672066.664131   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672066.664140   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672066.664555   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672066.664584   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672066.665489   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672066.666113   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672066.666554   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672066.666824   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672066.667579   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672066.667634   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672066.668028   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 33\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672066.668192   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp8kjn0f6o/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672066.668389   32914 kernel.cc:895] Train model\nI0000 00:00:1766672067.126994   32914 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64073\nI0000 00:00:1766672067.132208   32914 kernel.cc:926] Export model in log directory: /tmp/tmp8kjn0f6o with prefix 9ea0650e9b5a44e9\nI0000 00:00:1766672067.134916   32914 kernel.cc:944] Save model in resources\nI0000 00:00:1766672067.136679   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.64073\n\nAccuracy: 0.884615  CI95[W][0 1]\nErrorRate: : 0.115385\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  58   2\n2   7  11\nTotal: 78\n\n\nI0000 00:00:1766672067.801747   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672067.801791   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672067.801801   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672067.802270   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672067.802295   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672067.803132   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672067.803658   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672067.803895   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672067.804170   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672067.804836   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672067.804881   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672067.805294   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 34\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672067.805404   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpkbv5psk_/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672067.805569   33447 kernel.cc:895] Train model\nI0000 00:00:1766672068.118874   33447 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891668\nI0000 00:00:1766672068.123143   33447 kernel.cc:926] Export model in log directory: /tmp/tmpkbv5psk_ with prefix 2afcf88cb8094f5e\nI0000 00:00:1766672068.125319   33447 kernel.cc:944] Save model in resources\nI0000 00:00:1766672068.127123   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.891668\n\nAccuracy: 0.773585  CI95[W][0 1]\nErrorRate: : 0.226415\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  60   8\n2  16  22\nTotal: 106\n\n\nI0000 00:00:1766672068.792816   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672068.792857   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672068.792868   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672068.793380   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672068.793401   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672068.794540   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672068.795208   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672068.795500   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672068.795823   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672068.796576   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672068.796626   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672068.797092   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 35\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672068.797206   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpk17c6d6e/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672068.797397   33824 kernel.cc:895] Train model\nI0000 00:00:1766672069.092772   33824 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.73631\nI0000 00:00:1766672069.097055   33824 kernel.cc:926] Export model in log directory: /tmp/tmpk17c6d6e with prefix 9e7a396ead264d2b\nI0000 00:00:1766672069.099141   33824 kernel.cc:944] Save model in resources\nI0000 00:00:1766672069.100943   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.73631\n\nAccuracy: 0.845238  CI95[W][0 1]\nErrorRate: : 0.154762\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  51   4\n2   9  20\nTotal: 84\n\n\nI0000 00:00:1766672069.793163   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672069.793202   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672069.793212   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672069.793648   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672069.793675   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672069.794571   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672069.795113   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672069.795340   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672069.795635   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672069.796387   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672069.796436   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672069.796787   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 36\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672069.796912   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpqiqdhbl6/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672069.797078   34185 kernel.cc:895] Train model\nI0000 00:00:1766672070.269176   34185 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.99923\nI0000 00:00:1766672070.274869   34185 kernel.cc:926] Export model in log directory: /tmp/tmpqiqdhbl6 with prefix 7e6e6817a8f4498e\nI0000 00:00:1766672070.277939   34185 kernel.cc:944] Save model in resources\nI0000 00:00:1766672070.279913   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.99923\n\nAccuracy: 0.7625  CI95[W][0 1]\nErrorRate: : 0.2375\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  39   4\n2  15  22\nTotal: 80\n\n\nI0000 00:00:1766672070.959912   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672070.959956   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672070.959970   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672070.960684   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672070.960717   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672070.961765   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672070.962373   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672070.962644   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672070.962921   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672070.963599   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672070.963644   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672070.964026   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 37\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672070.964149   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp9giyoq20/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672070.964320   34754 kernel.cc:895] Train model\nI0000 00:00:1766672071.292626   34754 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85605\nI0000 00:00:1766672071.296731   34754 kernel.cc:926] Export model in log directory: /tmp/tmp9giyoq20 with prefix cf05434c9d9d4a4e\nI0000 00:00:1766672071.298747   34754 kernel.cc:944] Save model in resources\nI0000 00:00:1766672071.300497   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.85605\n\nAccuracy: 0.795455  CI95[W][0 1]\nErrorRate: : 0.204545\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  44   7\n2  11  26\nTotal: 88\n\n\nI0000 00:00:1766672071.965838   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672071.965882   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672071.965892   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672071.966321   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672071.966340   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672071.967339   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672071.967877   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672071.968143   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672071.968403   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672071.969043   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672071.969093   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672071.969507   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 38\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672071.969610   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpn77d8by2/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672071.969846   35163 kernel.cc:895] Train model\nI0000 00:00:1766672072.403623   35163 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65942\nI0000 00:00:1766672072.409127   35163 kernel.cc:926] Export model in log directory: /tmp/tmpn77d8by2 with prefix f853aa23f2cf46ce\nI0000 00:00:1766672072.412500   35163 kernel.cc:944] Save model in resources\nI0000 00:00:1766672072.414309   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.65942\n\nAccuracy: 0.861702  CI95[W][0 1]\nErrorRate: : 0.138298\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  55   5\n2   8  26\nTotal: 94\n\n\nI0000 00:00:1766672072.442847   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672073.080095   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672073.080142   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672073.080155   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672073.080638   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672073.080662   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672073.081676   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672073.082306   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672073.082659   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672073.082931   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672073.083642   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672073.083704   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672073.084181   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 39\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672073.084291   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpxu0mzua8/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672073.084447   35712 kernel.cc:895] Train model\nI0000 00:00:1766672073.516751   35712 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.612714\nI0000 00:00:1766672073.522098   35712 kernel.cc:926] Export model in log directory: /tmp/tmpxu0mzua8 with prefix 5b91802bf2a5446e\nI0000 00:00:1766672073.524942   35712 kernel.cc:944] Save model in resources\nI0000 00:00:1766672073.526765   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.612714\n\nAccuracy: 0.857143  CI95[W][0 1]\nErrorRate: : 0.142857\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  41   4\n2   6  19\nTotal: 70\n\n\nI0000 00:00:1766672074.194829   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672074.194873   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672074.194883   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672074.195327   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672074.195344   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672074.196163   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672074.196702   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672074.196907   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672074.197202   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672074.197829   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672074.197875   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672074.198278   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 40\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672074.198408   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpllee5848/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672074.198634   36237 kernel.cc:895] Train model\nI0000 00:00:1766672074.406854   36237 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.807169\nI0000 00:00:1766672074.410195   36237 kernel.cc:926] Export model in log directory: /tmp/tmpllee5848 with prefix e178405dbe8f408a\nI0000 00:00:1766672074.411483   36237 kernel.cc:944] Save model in resources\nI0000 00:00:1766672074.413358   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.807169\n\nAccuracy: 0.86  CI95[W][0 1]\nErrorRate: : 0.14\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  60   4\n2  10  26\nTotal: 100\n\n\nI0000 00:00:1766672075.068274   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672075.068318   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672075.068328   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672075.068780   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672075.068809   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672075.069656   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672075.070215   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672075.070460   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672075.070782   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672075.071488   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672075.071542   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672075.071879   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 41\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672075.071993   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp4rny5teq/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672075.072204   36506 kernel.cc:895] Train model\nI0000 00:00:1766672075.555482   36506 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.798221\nI0000 00:00:1766672075.561312   36506 kernel.cc:926] Export model in log directory: /tmp/tmp4rny5teq with prefix 3cc5229dfb0d40e1\nI0000 00:00:1766672075.564615   36506 kernel.cc:944] Save model in resources\nI0000 00:00:1766672075.566571   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.798221\n\nAccuracy: 0.819277  CI95[W][0 1]\nErrorRate: : 0.180723\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  46   5\n2  10  22\nTotal: 83\n\n\nI0000 00:00:1766672076.243867   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672076.243911   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672076.243922   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672076.244422   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672076.244444   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672076.245264   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672076.245760   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672076.245993   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672076.246285   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672076.246937   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672076.246984   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672076.247389   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 42\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672076.247504   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpwxrk3rey/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672076.247669   37111 kernel.cc:895] Train model\nI0000 00:00:1766672076.590654   37111 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.878562\nI0000 00:00:1766672076.595118   37111 kernel.cc:926] Export model in log directory: /tmp/tmpwxrk3rey with prefix 8c17a805f634404d\nI0000 00:00:1766672076.597395   37111 kernel.cc:944] Save model in resources\nI0000 00:00:1766672076.599444   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.878562\n\nAccuracy: 0.815534  CI95[W][0 1]\nErrorRate: : 0.184466\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  52   8\n2  11  32\nTotal: 103\n\n\nI0000 00:00:1766672077.280248   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672077.280289   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672077.280299   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672077.280784   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672077.280809   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672077.281819   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672077.282453   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672077.282704   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672077.282980   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672077.283671   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672077.283731   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672077.284191   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 43\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672077.284306   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpigon67b8/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672077.284480   37524 kernel.cc:895] Train model\nI0000 00:00:1766672077.845875   37524 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.716406\nI0000 00:00:1766672077.852763   37524 kernel.cc:926] Export model in log directory: /tmp/tmpigon67b8 with prefix 1b1fc06198354deb\nI0000 00:00:1766672077.856481   37524 kernel.cc:944] Save model in resources\nI0000 00:00:1766672077.858460   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.716406\n\nAccuracy: 0.841463  CI95[W][0 1]\nErrorRate: : 0.158537\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  47   3\n2  10  22\nTotal: 82\n\n\nI0000 00:00:1766672078.550798   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672078.550840   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672078.550850   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672078.551334   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672078.551351   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672078.552276   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672078.552784   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672078.553033   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672078.553313   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672078.554064   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672078.554121   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672078.554567   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 44\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672078.554680   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpp4bmsuaz/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672078.554864   38189 kernel.cc:895] Train model\nI0000 00:00:1766672078.905432   38189 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.94556\nI0000 00:00:1766672078.910801   38189 kernel.cc:926] Export model in log directory: /tmp/tmpp4bmsuaz with prefix 055b76e1033145ac\nI0000 00:00:1766672078.913065   38189 kernel.cc:944] Save model in resources\nI0000 00:00:1766672078.914928   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.94556\n\nAccuracy: 0.758621  CI95[W][0 1]\nErrorRate: : 0.241379\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  43   8\n2  13  23\nTotal: 87\n\n\nI0000 00:00:1766672079.627115   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672079.627158   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672079.627168   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672079.627569   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672079.627591   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672079.628478   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672079.629014   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672079.629280   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672079.629558   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672079.630539   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672079.630604   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672079.631069   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 45\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672079.631224   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpay4lz9l_/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672079.631410   38606 kernel.cc:895] Train model\nI0000 00:00:1766672079.829317   38606 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.893699\nI0000 00:00:1766672079.832319   38606 kernel.cc:926] Export model in log directory: /tmp/tmpay4lz9l_ with prefix 376ad97cb02841bb\nI0000 00:00:1766672079.833463   38606 kernel.cc:944] Save model in resources\nI0000 00:00:1766672079.835327   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.893699\n\nAccuracy: 0.831461  CI95[W][0 1]\nErrorRate: : 0.168539\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  51   6\n2   9  23\nTotal: 89\n\n\nI0000 00:00:1766672081.124737   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672081.124781   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672081.124799   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672081.125411   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672081.125441   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672081.126718   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672081.127298   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672081.127673   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672081.127941   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672081.128721   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672081.128772   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672081.129176   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 46\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672081.129294   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpqgotipd8/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672081.129468   38835 kernel.cc:895] Train model\nI0000 00:00:1766672081.678824   38835 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.795015\nI0000 00:00:1766672081.684500   38835 kernel.cc:926] Export model in log directory: /tmp/tmpqgotipd8 with prefix 1056d793d26f4ba6\nI0000 00:00:1766672081.687779   38835 kernel.cc:944] Save model in resources\nI0000 00:00:1766672081.689753   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.795015\n\nAccuracy: 0.823529  CI95[W][0 1]\nErrorRate: : 0.176471\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  66   8\n2  13  32\nTotal: 119\n\n\nI0000 00:00:1766672082.433688   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672082.433734   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672082.433751   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672082.434280   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672082.434309   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672082.435531   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672082.436172   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672082.436428   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672082.436697   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672082.437458   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672082.437511   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672082.437944   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 47\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672082.438116   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp0_vuxcb5/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672082.438342   39440 kernel.cc:895] Train model\nI0000 00:00:1766672082.904477   39440 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62117\nI0000 00:00:1766672082.909798   39440 kernel.cc:926] Export model in log directory: /tmp/tmp0_vuxcb5 with prefix 303ffdac40854cc0\nI0000 00:00:1766672082.912698   39440 kernel.cc:944] Save model in resources\nI0000 00:00:1766672082.914746   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.62117\n\nAccuracy: 0.890411  CI95[W][0 1]\nErrorRate: : 0.109589\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   5\n2   3  17\nTotal: 73\n\n\nI0000 00:00:1766672082.946387   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672083.651195   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672083.651245   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672083.651258   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672083.651670   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672083.651705   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672083.652804   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672083.653448   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672083.653711   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672083.654061   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672083.654735   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672083.654783   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672083.655188   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 48\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672083.655339   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpr5fuzq5r/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672083.655527   39973 kernel.cc:895] Train model\nI0000 00:00:1766672083.875219   39973 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864051\nI0000 00:00:1766672083.878445   39973 kernel.cc:926] Export model in log directory: /tmp/tmpr5fuzq5r with prefix 462ba50fb63d4a9d\nI0000 00:00:1766672083.880084   39973 kernel.cc:944] Save model in resources\nI0000 00:00:1766672083.882137   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.864051\n\nAccuracy: 0.822917  CI95[W][0 1]\nErrorRate: : 0.177083\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   6\n2  11  31\nTotal: 96\n\n\nI0000 00:00:1766672084.589398   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672084.589445   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672084.589456   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672084.589846   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672084.589862   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672084.590851   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672084.591410   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672084.591628   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672084.591928   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672084.592767   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672084.592827   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672084.593196   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 49\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672084.593315   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpcqedn7vk/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672084.593573   40234 kernel.cc:895] Train model\nI0000 00:00:1766672084.867310   40234 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.733037\nI0000 00:00:1766672084.871047   40234 kernel.cc:926] Export model in log directory: /tmp/tmpcqedn7vk with prefix 8d235115d781483f\nI0000 00:00:1766672084.872776   40234 kernel.cc:944] Save model in resources\nI0000 00:00:1766672084.874703   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.733037\n\nAccuracy: 0.831683  CI95[W][0 1]\nErrorRate: : 0.168317\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  61   3\n2  14  23\nTotal: 101\n\n\nI0000 00:00:1766672085.578576   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672085.578625   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672085.578647   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672085.579190   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672085.579213   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672085.580168   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672085.580743   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672085.580988   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672085.581324   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672085.582019   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672085.582072   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672085.582456   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 50\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672085.582567   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp6xxlxsnm/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672085.582762   40571 kernel.cc:895] Train model\nI0000 00:00:1766672086.002339   40571 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.72743\nI0000 00:00:1766672086.007401   40571 kernel.cc:926] Export model in log directory: /tmp/tmp6xxlxsnm with prefix b61c1f9604c74ea4\nI0000 00:00:1766672086.010489   40571 kernel.cc:944] Save model in resources\nI0000 00:00:1766672086.012509   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.72743\n\nAccuracy: 0.818182  CI95[W][0 1]\nErrorRate: : 0.181818\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  37   7\n2   7  26\nTotal: 77\n\n\nI0000 00:00:1766672086.713752   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672086.713807   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672086.713823   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672086.714439   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672086.714474   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672086.715399   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672086.715957   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672086.716238   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672086.716515   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672086.717178   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672086.717225   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672086.717567   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 51\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672086.717673   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpopg0hrcn/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672086.717840   41068 kernel.cc:895] Train model\nI0000 00:00:1766672087.266273   41068 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.760783\nI0000 00:00:1766672087.272266   41068 kernel.cc:926] Export model in log directory: /tmp/tmpopg0hrcn with prefix a4e5f91a90a14569\nI0000 00:00:1766672087.275495   41068 kernel.cc:944] Save model in resources\nI0000 00:00:1766672087.277656   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.760783\n\nAccuracy: 0.852632  CI95[W][0 1]\nErrorRate: : 0.147368\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  53   8\n2   6  28\nTotal: 95\n\n\nI0000 00:00:1766672087.980572   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672087.980618   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672087.980633   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672087.981190   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672087.981214   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672087.982147   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672087.982665   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672087.982867   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672087.983168   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672087.983861   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672087.983906   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672087.984284   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 52\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672087.984453   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpsjdhbxfy/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672087.984611   41689 kernel.cc:895] Train model\nI0000 00:00:1766672088.297582   41689 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.918049\nI0000 00:00:1766672088.301461   41689 kernel.cc:926] Export model in log directory: /tmp/tmpsjdhbxfy with prefix 0d93814597244973\nI0000 00:00:1766672088.303476   41689 kernel.cc:944] Save model in resources\nI0000 00:00:1766672088.305653   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.918049\n\nAccuracy: 0.772727  CI95[W][0 1]\nErrorRate: : 0.227273\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  42   4\n2  16  26\nTotal: 88\n\n\nI0000 00:00:1766672088.980178   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672088.980221   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672088.980232   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672088.980688   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672088.980714   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672088.981633   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672088.982176   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672088.982397   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672088.982683   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672088.983375   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672088.983421   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672088.983803   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 53\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672088.983908   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpn9wgaq_j/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672088.984084   42054 kernel.cc:895] Train model\nI0000 00:00:1766672089.294220   42054 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.764257\nI0000 00:00:1766672089.298265   42054 kernel.cc:926] Export model in log directory: /tmp/tmpn9wgaq_j with prefix 9e33d16d077a4e1d\nI0000 00:00:1766672089.300170   42054 kernel.cc:944] Save model in resources\nI0000 00:00:1766672089.302030   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.764257\n\nAccuracy: 0.855556  CI95[W][0 1]\nErrorRate: : 0.144444\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   7\n2   6  29\nTotal: 90\n\n\nI0000 00:00:1766672090.003620   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672090.003662   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672090.003676   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672090.004221   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672090.004243   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672090.005290   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672090.005887   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672090.006184   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672090.006485   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672090.007179   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672090.007227   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672090.007592   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 54\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672090.007697   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpmnupj482/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672090.007867   42399 kernel.cc:895] Train model\nI0000 00:00:1766672090.192800   42399 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89267\nI0000 00:00:1766672090.195723   42399 kernel.cc:926] Export model in log directory: /tmp/tmpmnupj482 with prefix bab1a6f499874f53\nI0000 00:00:1766672090.196766   42399 kernel.cc:944] Save model in resources\nI0000 00:00:1766672090.198783   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.89267\n\nAccuracy: 0.848837  CI95[W][0 1]\nErrorRate: : 0.151163\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  53   4\n2   9  20\nTotal: 86\n\n\nI0000 00:00:1766672090.864990   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672090.865052   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672090.865066   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672090.865595   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672090.865619   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672090.866505   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672090.867200   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672090.867558   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672090.867844   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672090.868723   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672090.868780   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672090.869318   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 55\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672090.869429   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpz3x2v8is/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672090.869606   42632 kernel.cc:895] Train model\nI0000 00:00:1766672091.378021   42632 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629973\nI0000 00:00:1766672091.383885   42632 kernel.cc:926] Export model in log directory: /tmp/tmpz3x2v8is with prefix 418a665d87e54bf4\nI0000 00:00:1766672091.387044   42632 kernel.cc:944] Save model in resources\nI0000 00:00:1766672091.388818   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.629973\n\nAccuracy: 0.849462  CI95[W][0 1]\nErrorRate: : 0.150538\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  52   5\n2   9  27\nTotal: 93\n\n\nI0000 00:00:1766672091.418371   17899 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\nI0000 00:00:1766672092.065689   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672092.065731   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672092.065746   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672092.066188   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672092.066208   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672092.067459   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672092.068057   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672092.068323   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672092.068637   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672092.069344   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672092.069397   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672092.069799   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 56\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672092.069922   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpz5s1teqk/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672092.070137   43221 kernel.cc:895] Train model\nI0000 00:00:1766672092.449963   43221 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.784389\nI0000 00:00:1766672092.454531   43221 kernel.cc:926] Export model in log directory: /tmp/tmpz5s1teqk with prefix 80fb22b1a4ca4bbf\nI0000 00:00:1766672092.456850   43221 kernel.cc:944] Save model in resources\nI0000 00:00:1766672092.458651   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.784389\n\nAccuracy: 0.823529  CI95[W][0 1]\nErrorRate: : 0.176471\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  54   8\n2  10  30\nTotal: 102\n\n\nI0000 00:00:1766672093.126163   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672093.126201   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672093.126211   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672093.126610   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672093.126625   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672093.127571   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672093.128168   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672093.128391   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672093.128675   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672093.129361   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672093.129406   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672093.129782   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 57\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672093.129890   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmplalca9wb/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672093.130123   43682 kernel.cc:895] Train model\nI0000 00:00:1766672093.349785   43682 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.974879\nI0000 00:00:1766672093.352984   43682 kernel.cc:926] Export model in log directory: /tmp/tmplalca9wb with prefix 8a5845cd304748bf\nI0000 00:00:1766672093.354228   43682 kernel.cc:944] Save model in resources\nI0000 00:00:1766672093.355978   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.974879\n\nAccuracy: 0.776471  CI95[W][0 1]\nErrorRate: : 0.223529\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  42   7\n2  12  24\nTotal: 85\n\n\nI0000 00:00:1766672093.375102   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672094.022877   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672094.022918   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672094.022932   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672094.023468   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672094.023495   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672094.024748   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672094.025477   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672094.025861   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672094.026180   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672094.026853   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672094.026899   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672094.027295   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 58\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672094.027410   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpcdnag4aq/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672094.027581   43939 kernel.cc:895] Train model\nI0000 00:00:1766672094.285852   43939 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.901905\nI0000 00:00:1766672094.289363   43939 kernel.cc:926] Export model in log directory: /tmp/tmpcdnag4aq with prefix 0b083996df7647f8\nI0000 00:00:1766672094.290870   43939 kernel.cc:944] Save model in resources\nI0000 00:00:1766672094.292731   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.901905\n\nAccuracy: 0.823529  CI95[W][0 1]\nErrorRate: : 0.176471\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  59   5\n2  13  25\nTotal: 102\n\n\nI0000 00:00:1766672094.966686   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672094.966731   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672094.966742   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672094.967229   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672094.967248   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672094.968277   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672094.968835   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672094.969101   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672094.969395   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672094.970066   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672094.970113   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672094.970462   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 59\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672094.970563   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpkyvty2bl/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672094.970776   44256 kernel.cc:895] Train model\nI0000 00:00:1766672095.317156   44256 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.809279\nI0000 00:00:1766672095.321476   44256 kernel.cc:926] Export model in log directory: /tmp/tmpkyvty2bl with prefix 6a33c9557f5d4cee\nI0000 00:00:1766672095.323733   44256 kernel.cc:944] Save model in resources\nI0000 00:00:1766672095.325698   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.809279\n\nAccuracy: 0.830769  CI95[W][0 1]\nErrorRate: : 0.169231\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  37   1\n2  10  17\nTotal: 65\n\n\nI0000 00:00:1766672095.992467   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672095.992508   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672095.992521   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672095.993085   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672095.993109   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672095.993970   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672095.994527   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672095.994807   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672095.995106   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672095.995742   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672095.995787   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672095.996219   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 60\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672095.996320   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmptzqjkr7r/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672095.996501   44661 kernel.cc:895] Train model\nI0000 00:00:1766672096.355723   44661 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.74376\nI0000 00:00:1766672096.360332   44661 kernel.cc:926] Export model in log directory: /tmp/tmptzqjkr7r with prefix dac4598f2ed64ff5\nI0000 00:00:1766672096.362741   44661 kernel.cc:944] Save model in resources\nI0000 00:00:1766672096.364680   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.74376\n\nAccuracy: 0.853659  CI95[W][0 1]\nErrorRate: : 0.146341\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  49   7\n2   5  21\nTotal: 82\n\n\nI0000 00:00:1766672097.030805   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672097.030846   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672097.030856   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672097.031354   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672097.031379   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672097.032266   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672097.032759   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672097.032989   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672097.033253   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672097.033855   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672097.033899   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672097.034302   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 61\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672097.034406   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp6pv9u_f2/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672097.034540   45098 kernel.cc:895] Train model\nI0000 00:00:1766672097.266943   45098 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855299\nI0000 00:00:1766672097.270572   45098 kernel.cc:926] Export model in log directory: /tmp/tmp6pv9u_f2 with prefix e280a4b5478d450c\nI0000 00:00:1766672097.271922   45098 kernel.cc:944] Save model in resources\nI0000 00:00:1766672097.273884   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.855299\n\nAccuracy: 0.788235  CI95[W][0 1]\nErrorRate: : 0.211765\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   4\n2  14  19\nTotal: 85\n\n\nI0000 00:00:1766672097.950256   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672097.950296   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672097.950310   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672097.950819   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672097.950841   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672097.951723   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672097.952303   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672097.952558   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672097.952850   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672097.953531   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672097.953576   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672097.953935   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 62\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672097.954073   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpncfkcpp8/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672097.954259   45371 kernel.cc:895] Train model\nI0000 00:00:1766672098.385565   45371 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.770603\nI0000 00:00:1766672098.390892   45371 kernel.cc:926] Export model in log directory: /tmp/tmpncfkcpp8 with prefix c8213ce081ae4471\nI0000 00:00:1766672098.393632   45371 kernel.cc:944] Save model in resources\nI0000 00:00:1766672098.395509   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.770603\n\nAccuracy: 0.772152  CI95[W][0 1]\nErrorRate: : 0.227848\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  43   5\n2  13  18\nTotal: 79\n\n\nI0000 00:00:1766672099.067530   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672099.067580   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672099.067592   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672099.068084   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672099.068101   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672099.068902   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672099.069462   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672099.069712   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672099.069987   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672099.070704   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672099.070753   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672099.071115   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 63\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672099.071240   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpnffg1m_q/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672099.071434   45872 kernel.cc:895] Train model\nI0000 00:00:1766672099.412835   45872 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.816591\nI0000 00:00:1766672099.417284   45872 kernel.cc:926] Export model in log directory: /tmp/tmpnffg1m_q with prefix 6c1b461b6b754eac\nI0000 00:00:1766672099.419503   45872 kernel.cc:944] Save model in resources\nI0000 00:00:1766672099.421518   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.816591\n\nAccuracy: 0.847826  CI95[W][0 1]\nErrorRate: : 0.152174\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  47   3\n2  11  31\nTotal: 92\n\n\nI0000 00:00:1766672100.113131   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672100.113172   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672100.113182   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672100.113592   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672100.113616   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672100.114502   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672100.115049   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672100.115307   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672100.115568   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672100.116244   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672100.116295   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672100.116664   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 64\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672100.116785   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpntkfx44d/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672100.116941   46277 kernel.cc:895] Train model\nI0000 00:00:1766672100.413066   46277 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.769799\nI0000 00:00:1766672100.417114   46277 kernel.cc:926] Export model in log directory: /tmp/tmpntkfx44d with prefix a46dbdbd7cf64a57\nI0000 00:00:1766672100.418935   46277 kernel.cc:944] Save model in resources\nI0000 00:00:1766672100.420760   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.769799\n\nAccuracy: 0.802083  CI95[W][0 1]\nErrorRate: : 0.197917\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  51   7\n2  12  26\nTotal: 96\n\n\nI0000 00:00:1766672101.105146   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672101.105186   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672101.105196   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672101.105620   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672101.105648   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672101.106555   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672101.107124   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672101.107386   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672101.107782   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672101.108560   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672101.108647   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672101.109072   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 65\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672101.109193   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpa2ryu5ox/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672101.109369   46646 kernel.cc:895] Train model\nI0000 00:00:1766672101.327956   46646 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85509\nI0000 00:00:1766672101.331217   46646 kernel.cc:926] Export model in log directory: /tmp/tmpa2ryu5ox with prefix 67f52dd842014019\nI0000 00:00:1766672101.332546   46646 kernel.cc:944] Save model in resources\nI0000 00:00:1766672101.334613   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.85509\n\nAccuracy: 0.819277  CI95[W][0 1]\nErrorRate: : 0.180723\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  42   7\n2   8  26\nTotal: 83\n\n\nI0000 00:00:1766672102.021482   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672102.021524   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672102.021534   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672102.021839   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672102.021849   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672102.022909   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672102.023486   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672102.023731   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672102.024044   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672102.024712   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672102.024757   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672102.025165   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 66\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672102.025292   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpd5_e2w8v/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672102.025460   46915 kernel.cc:895] Train model\nI0000 00:00:1766672102.287266   46915 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.884085\nI0000 00:00:1766672102.291125   46915 kernel.cc:926] Export model in log directory: /tmp/tmpd5_e2w8v with prefix 8b41ea5c8cc94274\nI0000 00:00:1766672102.293183   46915 kernel.cc:944] Save model in resources\nI0000 00:00:1766672102.294949   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.884085\n\nAccuracy: 0.804598  CI95[W][0 1]\nErrorRate: : 0.195402\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  47   4\n2  13  23\nTotal: 87\n\n\nI0000 00:00:1766672102.971557   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672102.971597   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672102.971607   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672102.972020   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672102.972047   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672102.972888   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672102.973435   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672102.973657   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672102.973943   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672102.974635   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672102.974682   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672102.975051   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 67\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672102.975183   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpmxgsm7k9/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672102.975328   47224 kernel.cc:895] Train model\nI0000 00:00:1766672103.570262   47224 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.723846\nI0000 00:00:1766672103.580686   47224 kernel.cc:926] Export model in log directory: /tmp/tmpmxgsm7k9 with prefix e977b28d93284cb0\nI0000 00:00:1766672103.584895   47224 kernel.cc:944] Save model in resources\nI0000 00:00:1766672103.586779   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.723846\n\nAccuracy: 0.868132  CI95[W][0 1]\nErrorRate: : 0.131868\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  54   6\n2   6  25\nTotal: 91\n\n\nI0000 00:00:1766672103.622484   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672104.271584   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672104.271626   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672104.271640   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672104.272162   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672104.272191   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672104.273082   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672104.273677   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672104.273932   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672104.274257   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672104.275214   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672104.275269   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672104.275703   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 68\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672104.275822   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpigwj_yca/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672104.276018   47921 kernel.cc:895] Train model\nI0000 00:00:1766672104.695205   47921 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624368\nI0000 00:00:1766672104.700303   47921 kernel.cc:926] Export model in log directory: /tmp/tmpigwj_yca with prefix be5f3d2272904603\nI0000 00:00:1766672104.703088   47921 kernel.cc:944] Save model in resources\nI0000 00:00:1766672104.704903   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.624368\n\nAccuracy: 0.894118  CI95[W][0 1]\nErrorRate: : 0.105882\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  52   1\n2   8  24\nTotal: 85\n\n\nI0000 00:00:1766672105.373821   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672105.373865   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672105.373875   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672105.374390   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672105.374416   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672105.375426   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672105.375948   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672105.376203   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672105.376479   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672105.377403   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672105.377457   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672105.377826   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 69\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672105.377947   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpdm5yea5m/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672105.378159   48414 kernel.cc:895] Train model\nI0000 00:00:1766672105.648186   48414 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.937521\nI0000 00:00:1766672105.651710   48414 kernel.cc:926] Export model in log directory: /tmp/tmpdm5yea5m with prefix 50c1a1d81ec74435\nI0000 00:00:1766672105.653775   48414 kernel.cc:944] Save model in resources\nI0000 00:00:1766672105.655576   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.937521\n\nAccuracy: 0.717391  CI95[W][0 1]\nErrorRate: : 0.282609\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  43   9\n2  17  23\nTotal: 92\n\n\nI0000 00:00:1766672106.314264   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672106.314306   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672106.314316   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672106.314752   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672106.314773   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672106.315689   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672106.316244   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672106.316512   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672106.316766   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672106.317452   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672106.317497   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672106.317922   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 70\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672106.318057   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpadbcpl_k/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672106.318272   48739 kernel.cc:895] Train model\nI0000 00:00:1766672106.631487   48739 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.882152\nI0000 00:00:1766672106.635508   48739 kernel.cc:926] Export model in log directory: /tmp/tmpadbcpl_k with prefix ee75502802434a0d\nI0000 00:00:1766672106.637768   48739 kernel.cc:944] Save model in resources\nI0000 00:00:1766672106.639579   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.882152\n\nAccuracy: 0.777778  CI95[W][0 1]\nErrorRate: : 0.222222\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  47   5\n2  17  30\nTotal: 99\n\n\nI0000 00:00:1766672107.314902   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672107.314946   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672107.314956   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672107.315385   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672107.315403   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672107.316287   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672107.316826   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672107.317070   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672107.317354   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672107.318046   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672107.318094   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672107.318466   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 71\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672107.318613   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpq3_2emh9/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672107.318798   49124 kernel.cc:895] Train model\nI0000 00:00:1766672107.603257   49124 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.847731\nI0000 00:00:1766672107.607327   49124 kernel.cc:926] Export model in log directory: /tmp/tmpq3_2emh9 with prefix d780ebbcb90e44f1\nI0000 00:00:1766672107.609182   49124 kernel.cc:944] Save model in resources\nI0000 00:00:1766672107.611103   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.847731\n\nAccuracy: 0.809524  CI95[W][0 1]\nErrorRate: : 0.190476\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  39   7\n2   9  29\nTotal: 84\n\n\nI0000 00:00:1766672108.282074   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672108.282113   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672108.282124   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672108.282551   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672108.282577   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672108.283444   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672108.283985   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672108.284256   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672108.284533   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672108.285199   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672108.285246   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672108.285609   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 72\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672108.285711   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpafgo3dyv/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672108.285888   49473 kernel.cc:895] Train model\nI0000 00:00:1766672108.813639   49473 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855513\nI0000 00:00:1766672108.820456   49473 kernel.cc:926] Export model in log directory: /tmp/tmpafgo3dyv with prefix 3a45162536f04d90\nI0000 00:00:1766672108.823859   49473 kernel.cc:944] Save model in resources\nI0000 00:00:1766672108.825751   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.855513\n\nAccuracy: 0.822222  CI95[W][0 1]\nErrorRate: : 0.177778\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   6\n2  10  26\nTotal: 90\n\n\nI0000 00:00:1766672109.542109   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672109.542147   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672109.542158   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672109.542619   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672109.542641   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672109.543617   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672109.544276   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672109.544555   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672109.544823   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672109.545512   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672109.545559   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672109.545905   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 73\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672109.546022   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpm8rfqnd7/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672109.546225   50074 kernel.cc:895] Train model\nI0000 00:00:1766672109.821864   50074 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857951\nI0000 00:00:1766672109.825855   50074 kernel.cc:926] Export model in log directory: /tmp/tmpm8rfqnd7 with prefix c0f7541c564548ea\nI0000 00:00:1766672109.827580   50074 kernel.cc:944] Save model in resources\nI0000 00:00:1766672109.829415   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.857951\n\nAccuracy: 0.806452  CI95[W][0 1]\nErrorRate: : 0.193548\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  49   5\n2  13  26\nTotal: 93\n\n\nI0000 00:00:1766672110.497899   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672110.497943   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672110.497952   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672110.498400   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672110.498419   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672110.499356   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672110.499848   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672110.500087   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672110.500323   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672110.500919   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672110.500963   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672110.501343   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 74\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672110.501449   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp8usx09cb/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672110.501609   50411 kernel.cc:895] Train model\nI0000 00:00:1766672110.904384   50411 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689967\nI0000 00:00:1766672110.909431   50411 kernel.cc:926] Export model in log directory: /tmp/tmp8usx09cb with prefix c14cc31054d8463b\nI0000 00:00:1766672110.912122   50411 kernel.cc:944] Save model in resources\nI0000 00:00:1766672110.913912   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.689967\n\nAccuracy: 0.857143  CI95[W][0 1]\nErrorRate: : 0.142857\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  59   2\n2  11  19\nTotal: 91\n\n\nI0000 00:00:1766672111.591851   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672111.591892   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672111.591903   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672111.592358   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672111.592378   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672111.593337   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672111.593854   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672111.594099   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672111.594384   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672111.595074   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672111.595127   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672111.595458   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 75\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672111.595595   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpglk5kl03/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672111.595755   50896 kernel.cc:895] Train model\nI0000 00:00:1766672111.911865   50896 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.904818\nI0000 00:00:1766672111.916374   50896 kernel.cc:926] Export model in log directory: /tmp/tmpglk5kl03 with prefix 786d87ea1e2b460d\nI0000 00:00:1766672111.918523   50896 kernel.cc:944] Save model in resources\nI0000 00:00:1766672111.920373   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.904818\n\nAccuracy: 0.743902  CI95[W][0 1]\nErrorRate: : 0.256098\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  37   8\n2  13  24\nTotal: 82\n\n\nI0000 00:00:1766672112.594263   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672112.594303   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672112.594317   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672112.594842   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672112.594864   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672112.595783   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672112.596349   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672112.596625   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672112.596906   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672112.597575   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672112.597622   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672112.598064   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 76\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672112.598184   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpha_ss7zb/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672112.598459   51265 kernel.cc:895] Train model\nI0000 00:00:1766672112.813134   51265 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.994467\nI0000 00:00:1766672112.816638   51265 kernel.cc:926] Export model in log directory: /tmp/tmpha_ss7zb with prefix e9836fc2e1b245d9\nI0000 00:00:1766672112.817806   51265 kernel.cc:944] Save model in resources\nI0000 00:00:1766672112.819658   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.994467\n\nAccuracy: 0.757895  CI95[W][0 1]\nErrorRate: : 0.242105\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  47   8\n2  15  25\nTotal: 95\n\n\nI0000 00:00:1766672114.156500   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672114.156558   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672114.156573   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672114.157060   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672114.157085   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672114.158217   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672114.158914   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672114.159396   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672114.159730   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672114.160510   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672114.160568   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672114.161181   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 77\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672114.161325   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpu_spv705/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672114.161559   51514 kernel.cc:895] Train model\nI0000 00:00:1766672114.378362   51514 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836056\nI0000 00:00:1766672114.381805   51514 kernel.cc:926] Export model in log directory: /tmp/tmpu_spv705 with prefix c141303b48d744f0\nI0000 00:00:1766672114.383167   51514 kernel.cc:944] Save model in resources\nI0000 00:00:1766672114.385306   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.836056\n\nAccuracy: 0.847059  CI95[W][0 1]\nErrorRate: : 0.152941\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  51   7\n2   6  21\nTotal: 85\n\n\nI0000 00:00:1766672114.408720   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672115.171843   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672115.171892   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672115.171904   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672115.172353   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672115.172382   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672115.173554   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672115.174150   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672115.174418   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672115.174733   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672115.175481   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672115.175532   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672115.175981   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 78\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672115.176141   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpuiqw8rfx/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672115.176360   51783 kernel.cc:895] Train model\nI0000 00:00:1766672115.446603   51783 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806394\nI0000 00:00:1766672115.450127   51783 kernel.cc:926] Export model in log directory: /tmp/tmpuiqw8rfx with prefix f47e48b0316c4805\nI0000 00:00:1766672115.451749   51783 kernel.cc:944] Save model in resources\nI0000 00:00:1766672115.453688   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.806394\n\nAccuracy: 0.833333  CI95[W][0 1]\nErrorRate: : 0.166667\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  50   2\n2  11  15\nTotal: 78\n\n\nI0000 00:00:1766672116.181371   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672116.181418   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672116.181430   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672116.181825   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672116.181851   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672116.182921   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672116.183507   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672116.183756   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672116.184076   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672116.184768   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672116.184818   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672116.185208   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 79\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672116.185318   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpmsualfe0/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672116.185496   52100 kernel.cc:895] Train model\nI0000 00:00:1766672116.458141   52100 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.802796\nI0000 00:00:1766672116.461876   52100 kernel.cc:926] Export model in log directory: /tmp/tmpmsualfe0 with prefix fd0d531d117c44d2\nI0000 00:00:1766672116.463599   52100 kernel.cc:944] Save model in resources\nI0000 00:00:1766672116.465513   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.802796\n\nAccuracy: 0.830357  CI95[W][0 1]\nErrorRate: : 0.169643\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  68   9\n2  10  25\nTotal: 112\n\n\nI0000 00:00:1766672117.177636   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672117.177681   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672117.177698   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672117.178384   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672117.178416   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672117.179538   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672117.180248   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672117.180601   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672117.180911   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672117.181667   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672117.181720   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672117.182156   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 80\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672117.182269   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpt2pj9prl/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672117.182460   52441 kernel.cc:895] Train model\nI0000 00:00:1766672117.544870   52441 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.700988\nI0000 00:00:1766672117.549468   52441 kernel.cc:926] Export model in log directory: /tmp/tmpt2pj9prl with prefix 6a6bbfcf33084419\nI0000 00:00:1766672117.551776   52441 kernel.cc:944] Save model in resources\nI0000 00:00:1766672117.553782   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.700988\n\nAccuracy: 0.847222  CI95[W][0 1]\nErrorRate: : 0.152778\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  36   3\n2   8  25\nTotal: 72\n\n\nI0000 00:00:1766672118.271929   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672118.271986   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672118.272021   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672118.272469   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672118.272490   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672118.273514   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672118.274175   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672118.274432   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672118.274744   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672118.275482   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672118.275537   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672118.275940   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 81\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672118.276126   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpwj2r8432/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672118.276308   52866 kernel.cc:895] Train model\nI0000 00:00:1766672118.696544   52866 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.833355\nI0000 00:00:1766672118.701268   52866 kernel.cc:926] Export model in log directory: /tmp/tmpwj2r8432 with prefix fd3ac1a9c89245dd\nI0000 00:00:1766672118.703753   52866 kernel.cc:944] Save model in resources\nI0000 00:00:1766672118.705713   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.833355\n\nAccuracy: 0.819277  CI95[W][0 1]\nErrorRate: : 0.180723\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   6\n2   9  20\nTotal: 83\n\n\nI0000 00:00:1766672119.423389   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672119.423433   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672119.423450   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672119.423993   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672119.424045   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672119.424991   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672119.425662   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672119.426071   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672119.426474   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672119.427187   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672119.427238   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672119.427706   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 82\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672119.427858   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp38qetgcm/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672119.428040   53351 kernel.cc:895] Train model\nI0000 00:00:1766672119.803149   53351 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.742232\nI0000 00:00:1766672119.807606   53351 kernel.cc:926] Export model in log directory: /tmp/tmp38qetgcm with prefix 33df672725734fbd\nI0000 00:00:1766672119.809802   53351 kernel.cc:944] Save model in resources\nI0000 00:00:1766672119.811755   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.742232\n\nAccuracy: 0.85  CI95[W][0 1]\nErrorRate: : 0.15\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  55   7\n2   8  30\nTotal: 100\n\n\nI0000 00:00:1766672120.513330   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672120.513374   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672120.513386   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672120.513817   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672120.513845   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672120.514788   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672120.515362   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672120.515653   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672120.515937   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672120.516637   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672120.516686   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672120.517092   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 83\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672120.517255   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpsvmwv8hm/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672120.517422   53764 kernel.cc:895] Train model\nI0000 00:00:1766672120.852661   53764 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858547\nI0000 00:00:1766672120.856845   53764 kernel.cc:926] Export model in log directory: /tmp/tmpsvmwv8hm with prefix 31b4dcc80bea4525\nI0000 00:00:1766672120.858923   53764 kernel.cc:944] Save model in resources\nI0000 00:00:1766672120.860805   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.858547\n\nAccuracy: 0.791667  CI95[W][0 1]\nErrorRate: : 0.208333\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  34   6\n2   9  23\nTotal: 72\n\n\nI0000 00:00:1766672121.563050   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672121.563110   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672121.563126   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672121.563701   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672121.563731   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672121.564685   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672121.565283   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672121.565488   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672121.565785   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672121.566551   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672121.566612   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672121.567043   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 84\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672121.567245   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpan24x9_3/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672121.567393   54157 kernel.cc:895] Train model\nI0000 00:00:1766672122.090600   54157 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.923903\nI0000 00:00:1766672122.096529   54157 kernel.cc:926] Export model in log directory: /tmp/tmpan24x9_3 with prefix 8721821bd8e94310\nI0000 00:00:1766672122.100173   54157 kernel.cc:944] Save model in resources\nI0000 00:00:1766672122.102166   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.923903\n\nAccuracy: 0.733333  CI95[W][0 1]\nErrorRate: : 0.266667\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  32   8\n2  12  23\nTotal: 75\n\n\nI0000 00:00:1766672122.134288   17899 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\nI0000 00:00:1766672122.808384   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672122.808428   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672122.808442   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672122.808844   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672122.808860   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672122.809811   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672122.810373   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672122.810630   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672122.811107   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672122.811889   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672122.811942   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672122.812371   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 85\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672122.812501   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpoh_aexfw/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672122.812710   54758 kernel.cc:895] Train model\nI0000 00:00:1766672123.082523   54758 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.03532\nI0000 00:00:1766672123.086400   54758 kernel.cc:926] Export model in log directory: /tmp/tmpoh_aexfw with prefix 3b2af5cf3ba246e7\nI0000 00:00:1766672123.087942   54758 kernel.cc:944] Save model in resources\nI0000 00:00:1766672123.089901   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 1.03532\n\nAccuracy: 0.74359  CI95[W][0 1]\nErrorRate: : 0.25641\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  36   7\n2  13  22\nTotal: 78\n\n\nI0000 00:00:1766672123.777655   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672123.777703   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672123.777715   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672123.778120   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672123.778153   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672123.779045   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672123.779596   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672123.779825   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672123.780087   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672123.780737   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672123.780787   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672123.781245   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 86\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672123.781353   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp6_doh_4f/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672123.781515   55071 kernel.cc:895] Train model\nI0000 00:00:1766672124.301756   55071 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692466\nI0000 00:00:1766672124.307990   55071 kernel.cc:926] Export model in log directory: /tmp/tmp6_doh_4f with prefix 756de5bd8d0d46d1\nI0000 00:00:1766672124.311310   55071 kernel.cc:944] Save model in resources\nI0000 00:00:1766672124.313186   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.692466\n\nAccuracy: 0.79798  CI95[W][0 1]\nErrorRate: : 0.20202\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  56  10\n2  10  23\nTotal: 99\n\n\nI0000 00:00:1766672125.015761   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672125.015815   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672125.015834   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672125.016347   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672125.016369   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672125.017281   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672125.017846   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672125.018073   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672125.018366   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672125.019058   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672125.019111   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672125.019510   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 87\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672125.019651   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpcktv9i5_/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672125.019813   55672 kernel.cc:895] Train model\nI0000 00:00:1766672125.593179   55672 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695994\nI0000 00:00:1766672125.599895   55672 kernel.cc:926] Export model in log directory: /tmp/tmpcktv9i5_ with prefix 4d2d58470bb14c7e\nI0000 00:00:1766672125.603915   55672 kernel.cc:944] Save model in resources\nI0000 00:00:1766672125.605815   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.695994\n\nAccuracy: 0.894118  CI95[W][0 1]\nErrorRate: : 0.105882\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  42   4\n2   5  34\nTotal: 85\n\n\nI0000 00:00:1766672125.640345   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672126.289218   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672126.289262   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672126.289278   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672126.289809   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672126.289837   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672126.290828   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672126.291428   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672126.291706   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672126.292036   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672126.292731   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672126.292776   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672126.293184   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 88\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672126.293317   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpiavra33l/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672126.293507   56353 kernel.cc:895] Train model\nI0000 00:00:1766672126.674790   56353 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.729052\nI0000 00:00:1766672126.679542   56353 kernel.cc:926] Export model in log directory: /tmp/tmpiavra33l with prefix 2e0046466306462a\nI0000 00:00:1766672126.682173   56353 kernel.cc:944] Save model in resources\nI0000 00:00:1766672126.684054   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.729052\n\nAccuracy: 0.821782  CI95[W][0 1]\nErrorRate: : 0.178218\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  62  10\n2   8  21\nTotal: 101\n\n\nI0000 00:00:1766672127.368778   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672127.368821   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672127.368831   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672127.369325   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672127.369348   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672127.370216   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672127.370708   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672127.370890   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672127.371171   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672127.371785   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672127.371831   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672127.372196   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 89\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672127.372322   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpvdlhdkx7/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672127.372496   56830 kernel.cc:895] Train model\nI0000 00:00:1766672127.601904   56830 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.745917\nI0000 00:00:1766672127.605401   56830 kernel.cc:926] Export model in log directory: /tmp/tmpvdlhdkx7 with prefix b6c68348c22c490f\nI0000 00:00:1766672127.607403   56830 kernel.cc:944] Save model in resources\nI0000 00:00:1766672127.609391   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.745917\n\nAccuracy: 0.86747  CI95[W][0 1]\nErrorRate: : 0.13253\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  51   3\n2   8  21\nTotal: 83\n\n\nI0000 00:00:1766672128.282145   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672128.282189   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672128.282203   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672128.282761   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672128.282784   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672128.283671   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672128.284241   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672128.284579   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672128.284955   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672128.285675   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672128.285725   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672128.286187   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 90\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672128.286295   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpazojoeie/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672128.286497   57107 kernel.cc:895] Train model\nI0000 00:00:1766672128.662800   57107 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.715057\nI0000 00:00:1766672128.667441   57107 kernel.cc:926] Export model in log directory: /tmp/tmpazojoeie with prefix 8f3647356b7c485a\nI0000 00:00:1766672128.669759   57107 kernel.cc:944] Save model in resources\nI0000 00:00:1766672128.671549   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.715057\n\nAccuracy: 0.852273  CI95[W][0 1]\nErrorRate: : 0.147727\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  53   4\n2   9  22\nTotal: 88\n\n\nI0000 00:00:1766672129.349836   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672129.349878   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672129.349892   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672129.350445   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672129.350468   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672129.351379   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672129.351952   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672129.352202   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672129.352501   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672129.353188   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672129.353235   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672129.353666   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 91\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672129.353772   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpoxd84rf3/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672129.353974   57552 kernel.cc:895] Train model\nI0000 00:00:1766672129.656901   57552 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.878143\nI0000 00:00:1766672129.661375   57552 kernel.cc:926] Export model in log directory: /tmp/tmpoxd84rf3 with prefix 25fa94d9b59f4088\nI0000 00:00:1766672129.663127   57552 kernel.cc:944] Save model in resources\nI0000 00:00:1766672129.664921   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.878143\n\nAccuracy: 0.784091  CI95[W][0 1]\nErrorRate: : 0.215909\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  41   9\n2  10  28\nTotal: 88\n\n\nI0000 00:00:1766672130.342807   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672130.342850   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672130.342863   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672130.343459   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672130.343489   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672130.344383   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672130.344873   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672130.345122   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672130.345364   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672130.345986   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672130.346069   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672130.346399   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 92\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672130.346498   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp8ckh7n40/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672130.346664   57893 kernel.cc:895] Train model\nI0000 00:00:1766672130.914697   57893 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641747\nI0000 00:00:1766672130.920881   57893 kernel.cc:926] Export model in log directory: /tmp/tmp8ckh7n40 with prefix 29b1877c149d41fd\nI0000 00:00:1766672130.924607   57893 kernel.cc:944] Save model in resources\nI0000 00:00:1766672130.926415   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.641747\n\nAccuracy: 0.873684  CI95[W][0 1]\nErrorRate: : 0.126316\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  46   6\n2   6  37\nTotal: 95\n\n\nI0000 00:00:1766672131.611158   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672131.611201   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672131.611211   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672131.611592   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672131.611607   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672131.612480   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672131.612986   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672131.613233   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672131.613560   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672131.614304   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672131.614356   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672131.614688   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 93\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672131.614795   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpbr55h_5g/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672131.615099   58574 kernel.cc:895] Train model\nI0000 00:00:1766672131.974960   58574 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6908\nI0000 00:00:1766672131.979779   58574 kernel.cc:926] Export model in log directory: /tmp/tmpbr55h_5g with prefix c12e104e27af4cd0\nI0000 00:00:1766672131.982126   58574 kernel.cc:944] Save model in resources\nI0000 00:00:1766672131.983855   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.6908\n\nAccuracy: 0.851064  CI95[W][0 1]\nErrorRate: : 0.148936\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  56  10\n2   4  24\nTotal: 94\n\n\nI0000 00:00:1766672132.671083   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672132.671122   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672132.671136   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672132.671666   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672132.671691   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672132.672618   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672132.673207   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672132.673473   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672132.673746   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672132.674448   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672132.674492   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672132.674914   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 94\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672132.675042   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpo9avry2s/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672132.675203   59019 kernel.cc:895] Train model\nI0000 00:00:1766672132.939073   59019 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.964335\nI0000 00:00:1766672132.942783   59019 kernel.cc:926] Export model in log directory: /tmp/tmpo9avry2s with prefix 1da63041ce41455f\nI0000 00:00:1766672132.944521   59019 kernel.cc:944] Save model in resources\nI0000 00:00:1766672132.946473   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.964335\n\nAccuracy: 0.802817  CI95[W][0 1]\nErrorRate: : 0.197183\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  45   4\n2  10  12\nTotal: 71\n\n\nI0000 00:00:1766672133.617534   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672133.617573   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672133.617583   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672133.617981   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672133.618017   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672133.618835   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672133.619363   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672133.619592   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672133.619863   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672133.620526   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672133.620571   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672133.620946   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 95\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672133.621122   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpq7eiqdbc/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672133.621299   59344 kernel.cc:895] Train model\nI0000 00:00:1766672133.948862   59344 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.897095\nI0000 00:00:1766672133.953243   59344 kernel.cc:926] Export model in log directory: /tmp/tmpq7eiqdbc with prefix 12abb0bed2af44d2\nI0000 00:00:1766672133.955277   59344 kernel.cc:944] Save model in resources\nI0000 00:00:1766672133.957109   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.897095\n\nAccuracy: 0.823529  CI95[W][0 1]\nErrorRate: : 0.176471\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  48   7\n2   8  22\nTotal: 85\n\n\nI0000 00:00:1766672134.638875   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672134.638920   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672134.638930   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672134.639417   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672134.639435   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672134.640467   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672134.641055   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672134.641269   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672134.641560   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672134.642244   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672134.642292   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672134.642671   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 96\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672134.642846   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpq7xi7h7t/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672134.643041   59733 kernel.cc:895] Train model\nI0000 00:00:1766672135.008715   59733 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.714746\nI0000 00:00:1766672135.013559   59733 kernel.cc:926] Export model in log directory: /tmp/tmpq7xi7h7t with prefix 066c4834570e4b67\nI0000 00:00:1766672135.016223   59733 kernel.cc:944] Save model in resources\nI0000 00:00:1766672135.018147   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.714746\n\nAccuracy: 0.824176  CI95[W][0 1]\nErrorRate: : 0.175824\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  57   8\n2   8  18\nTotal: 91\n\n\nI0000 00:00:1766672135.715656   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672135.715701   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672135.715711   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672135.716081   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672135.716100   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672135.716957   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672135.717568   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672135.717794   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672135.718088   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672135.718708   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672135.718754   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672135.719164   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 97\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672135.719264   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmppv_ue3og/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672135.719415   60158 kernel.cc:895] Train model\nI0000 00:00:1766672135.947094   60158 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881163\nI0000 00:00:1766672135.950695   60158 kernel.cc:926] Export model in log directory: /tmp/tmppv_ue3og with prefix f321d09c93134883\nI0000 00:00:1766672135.952192   60158 kernel.cc:944] Save model in resources\nI0000 00:00:1766672135.953992   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.881163\n\nAccuracy: 0.813333  CI95[W][0 1]\nErrorRate: : 0.186667\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  47   5\n2   9  14\nTotal: 75\n\n\nI0000 00:00:1766672135.973622   17899 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\nI0000 00:00:1766672136.638780   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672136.638826   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672136.638842   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672136.639435   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672136.639463   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672136.640367   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672136.640873   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672136.641115   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672136.641417   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672136.642133   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672136.642187   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672136.642537   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 98\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672136.642646   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpf163k9nf/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672136.642851   60443 kernel.cc:895] Train model\nI0000 00:00:1766672136.942874   60443 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.781304\nI0000 00:00:1766672136.946921   60443 kernel.cc:926] Export model in log directory: /tmp/tmpf163k9nf with prefix 6b959b0ee2ed4095\nI0000 00:00:1766672136.948810   60443 kernel.cc:944] Save model in resources\nI0000 00:00:1766672136.950575   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.781304\n\nAccuracy: 0.829545  CI95[W][0 1]\nErrorRate: : 0.170455\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  45   6\n2   9  28\nTotal: 88\n\n\nI0000 00:00:1766672137.638367   17899 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1766672137.638409   17899 kernel.cc:783] Collect training examples\nI0000 00:00:1766672137.638419   17899 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1766672137.638909   17899 kernel.cc:401] Number of batches: 1\nI0000 00:00:1766672137.638933   17899 kernel.cc:402] Number of examples: 891\nI0000 00:00:1766672137.639789   17899 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672137.640330   17899 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672137.640567   17899 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672137.640854   17899 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1766672137.641693   17899 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1766672137.641761   17899 kernel.cc:818] Configure learner\nI0000 00:00:1766672137.642208   17899 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 99\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n    honest {\n      ratio_leaf_examples: 0.5\n      fixed_separation: false\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1766672137.642320   17899 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmprtmo84h1/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1766672137.642491   60800 kernel.cc:895] Train model\nI0000 00:00:1766672138.153498   60800 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.797904\nI0000 00:00:1766672138.159405   60800 kernel.cc:926] Export model in log directory: /tmp/tmprtmo84h1 with prefix eb8def30a27747a8\nI0000 00:00:1766672138.162623   60800 kernel.cc:944] Save model in resources\nI0000 00:00:1766672138.164530   17899 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.797904\n\nAccuracy: 0.822222  CI95[W][0 1]\nErrorRate: : 0.177778\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  39   6\n2  10  35\nTotal: 90\n\n\n","output_type":"stream"}],"execution_count":16},{"id":"4d84c8f2-5757-4f45-b3a2-1dd1b05ea177","cell_type":"code","source":"# Cell 8: Create submission\nsubmission = pd.DataFrame({\n    \"PassengerId\": serving_df[\"PassengerId\"],\n    \"Survived\": (predictions >= 0.5).astype(int)\n})\n\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:16:46.070539Z","iopub.execute_input":"2025-12-25T14:16:46.070887Z","iopub.status.idle":"2025-12-25T14:16:46.080290Z","shell.execute_reply.started":"2025-12-25T14:16:46.070861Z","shell.execute_reply":"2025-12-25T14:16:46.079327Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":17}]}